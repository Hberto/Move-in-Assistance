{"cells":[{"cell_type":"markdown","source":["# Classification with RandomForest\n","## Steps\n","  1. Introduction and Use-Case\n","  2. Dataset and preparation\n","  3. Classification\n","  4. Further Look and Conclusion"],"metadata":{"id":"bFRpe4pDKaes"}},{"cell_type":"markdown","source":["# Code (Data preprocessing)"],"metadata":{"id":"Z94hyUcCKyRI"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"gY3Y4maK6zDT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705061797669,"user_tz":-60,"elapsed":762542,"user":{"displayName":"H. Werner","userId":"11107641138698865980"}},"outputId":"68936c89-48ac-4e0e-f974-84b673d3143e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Install dependencies\n","!pip install --user shapely\n","!pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CFRKpkjoJ_DU","executionInfo":{"status":"ok","timestamp":1705061842840,"user_tz":-60,"elapsed":45200,"user":{"displayName":"H. Werner","userId":"11107641138698865980"}},"outputId":"3cabfaac-2415-4391-dda2-29fd3e112fa3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (2.0.2)\n","Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely) (1.23.5)\n","Collecting pyspark\n","  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=3f32eb6f27738229936e7d1a4cef69cceb91a0bf6244e764364d26c5733c9121\n","  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.0\n"]}]},{"cell_type":"code","source":["# PySpark Session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder\\\n","        .master(\"local\")\\\n","        .appName(\"Colab\")\\\n","        .config('spark.ui.port', '4050')\\\n","        .getOrCreate()"],"metadata":{"id":"Tnph3BPuKYaM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load Data\n","df_merged_nonan = spark.read.csv('/content/drive/MyDrive/DA_Data/Merged_Cleaned_Data/merged_featureset_nonan.csv', header=True)\n","df_merged_with_nan = spark.read.csv('/content/drive/MyDrive/DA_Data/Merged_Cleaned_Data/merged_featureset_with_nan.csv', header=True)\n","\n","df_merged_nonan.printSchema()\n","df_merged_nonan.show()\n","#df_merged_with_nan.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uOyJ-P27K9LG","executionInfo":{"status":"ok","timestamp":1705068485559,"user_tz":-60,"elapsed":1729,"user":{"displayName":"H. Werner","userId":"11107641138698865980"}},"outputId":"654eaa74-2ae9-4ac0-eb4d-559e6f235f56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Stadtteil: string (nullable = true)\n"," |-- Mietpreis pro qm: string (nullable = true)\n"," |-- Gruenflaeche: string (nullable = true)\n"," |-- AQI: string (nullable = true)\n"," |-- Fahrradhausanzahl: string (nullable = true)\n"," |-- Flaeche: string (nullable = true)\n"," |-- Anzahl_Punkte: string (nullable = true)\n","\n","+---------------+-----------------+------------------+------------------+-----------------+------------------+-------------+\n","|      Stadtteil| Mietpreis pro qm|      Gruenflaeche|               AQI|Fahrradhausanzahl|           Flaeche|Anzahl_Punkte|\n","+---------------+-----------------+------------------+------------------+-----------------+------------------+-------------+\n","|      Allermöhe| 9.67255494038344|           64.5282| 2.211251302234055|              0.0| 8.645889439254942|          0.0|\n","|     Alsterdorf|11.17867462862816|           43.2205|  2.16680208937899|              0.0| 3.152300871916889|       4698.0|\n","|     Altengamme| 9.47397938223054|            1.2187| 2.211251302234055|              0.0|15.605402117118146|       1639.0|\n","|Altona-Altstadt| 10.7202465514164|           30.2225|  2.16680208937899|              9.0| 2.716112276059931|       4796.0|\n","|    Altona-Nord|11.50444262953117| 8.260200000000001|  2.16680208937899|             45.0| 2.216384762735775|       2513.0|\n","|     Bahrenfeld|  10.330243759149|334.75890000000004|  2.16680208937899|              3.0|10.534082071963413|       8492.0|\n","|   Barmbek-Nord|10.35144739634928|           59.0004|  2.16680208937899|              4.0| 3.847326472204601|       6213.0|\n","|    Barmbek-Süd|10.51695632308143|31.269900000000003|  2.16680208937899|             10.0| 3.091089205445396|          0.0|\n","|      Bergedorf| 9.54203189360139|159.38060000000002| 2.211251302234055|              0.0|10.348868599966853|       8524.0|\n","|      Bergstedt|  9.8572182386084|           29.6124| 2.201276842716193|              0.0| 7.035939472827065|       4711.0|\n","|      Billbrook| 8.36472703045473|17.192400000000003|  2.16680208937899|              0.0| 6.285402738795647|       2618.0|\n","|      Billstedt| 8.85675465076737|          375.1621| 2.201276842716193|              0.0|16.912571877282463|      13282.0|\n","|     Billwerder| 9.83770511193352| 82.96470000000001| 2.201276842716193|              0.0| 9.460958972557059|        986.0|\n","|     Blankenese|11.76406665370848|           97.6823| 2.128148578061521|              1.0| 7.730078801894664|       3969.0|\n","|      Borgfelde|10.63493478307278|             6.046|  2.16680208937899|              0.0|0.8211273225779278|        913.0|\n","|       Bramfeld| 9.48662198077444|156.44169999999997|  2.16680208937899|              0.0| 10.06010830653727|       8658.0|\n","|          Cranz| 9.34747681550516|             0.585| 2.128148578061521|              0.0|1.3322265385786445|        571.0|\n","|       Curslack| 9.60493840705059|           18.7545| 2.211251302234055|              0.0|10.568284883301864|        930.0|\n","|       Dulsberg| 9.67903215123385|15.346900000000002|  2.16680208937899|              1.0|1.2235835655605425|       1873.0|\n","|     Duvenstedt| 10.6700167537834|            6.8367|2.1568195008705744|              0.0| 6.777426162388417|       3689.0|\n","+---------------+-----------------+------------------+------------------+-----------------+------------------+-------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"code","source":["# Checking Data\n","\n","#district_name = \"Barmbek Süd\"\n","\n","# Filter DataFrame for the specified district\n","#barmbek_sud_data = merged_social_data.filter(col(\"Stadtteil\") == district_name)\n","\n","# Show the DataFrame\n","#barmbek_sud_data.show()\n"],"metadata":{"id":"MzaoSKD0NUsC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cast Data to Double\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import col\n","\n","# Double\n","df_merged_nonan = df_merged_nonan.withColumn(\"Mietpreis pro qm\", df_merged_nonan[\"Mietpreis pro qm\"].cast(DoubleType()))\n","df_merged_nonan = df_merged_nonan.withColumn(\"Gruenflaeche\", df_merged_nonan[\"Mietpreis pro qm\"].cast(DoubleType()))\n","df_merged_nonan = df_merged_nonan.withColumn(\"AQI\", df_merged_nonan[\"AQI\"].cast(DoubleType()))\n","df_merged_nonan = df_merged_nonan.withColumn(\"Flaeche\", df_merged_nonan[\"Flaeche\"].cast(DoubleType()))\n","\n","#Integer\n","df_merged_nonan = df_merged_nonan.withColumn(\"Fahrradhausanzahl\", df_merged_nonan[\"Fahrradhausanzahl\"].cast(IntegerType()))\n","df_merged_nonan = df_merged_nonan.withColumn(\"Anzahl_Punkte\", df_merged_nonan[\"Anzahl_Punkte\"].cast(IntegerType()))\n","\n","# To Pandas\n","mer_nonan = df_merged_nonan.toPandas()"],"metadata":{"id":"hy9WcjRBMsJd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DataSet Preparation (Test, Train Data Set and Labeling)"],"metadata":{"id":"KtI-LW52xJdX"}},{"cell_type":"code","source":["# Dependencies\n","\n","# Data Processing\n","import pandas as pd\n","import numpy as np\n","\n","# Modelling\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n","from sklearn.model_selection import RandomizedSearchCV, train_test_split\n","from scipy.stats import randint\n","from sklearn.preprocessing import StandardScaler"],"metadata":{"id":"IUBzVIOPxVuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Labeling\n","le = LabelEncoder()\n","mer_nonan['Stadtteil'] = le.fit_transform(mer_nonan['Stadtteil'])\n","\n","# Split the data into features (X) and target (y)\n","#features_to_drop = ['Fahrradhausanzahl', 'Flaeche', 'Gruenflaeche','AQI']\n","X = mer_nonan.drop(['Stadtteil'], axis=1)  # Assuming 'Stadtteil' is the target\n","#X = mer_nonan.drop(['Stadtteil'] + features_to_drop, axis=1)  # Assuming 'Stadtteil' is the target\n","y = mer_nonan['Stadtteil']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(y_train.value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"JgmuWkrNx-U-","executionInfo":{"status":"error","timestamp":1705136503315,"user_tz":-60,"elapsed":18,"user":{"displayName":"H. Werner","userId":"11107641138698865980"}},"outputId":"510ad0cc-5560-46b9-db0f-0ef49447a6d3"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'LabelEncoder' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-baf2124b3679>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Labeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmer_nonan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stadtteil'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmer_nonan\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stadtteil'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Split the data into features (X) and target (y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'LabelEncoder' is not defined"]}]},{"cell_type":"code","source":["from ctypes import c_int64\n","from sklearn.ensemble import *\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from itertools import product\n","\n","\n","# Preprocessing with StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Train Model\n","rf = RandomForestClassifier(class_weight='balanced')\n","rf.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = rf.predict(X_test)\n","###############################################################################\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='macro')  # Specify the average parameter\n","recall = recall_score(y_test, y_pred, average='macro')  # Specify the average parameter\n","\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","\n","\n","# Check the distribution of predicted classes\n","print(\"Predicted Class Distribution:\")\n","print(pd.Series(y_pred).value_counts())\n","\n","# Explore the confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","\n","# Display feature importances\n","#feature_importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n","#print(\"Feature Importances:\")\n","#print(feature_importances)\n","\n","# Tree Visualisation\n","from sklearn.tree import export_graphviz\n","from IPython.display import Image\n","import graphviz\n","\n","# Export the first three decision trees from the forest\n","\n","for i in range(3):\n","    tree = rf.estimators_[i]\n","    dot_data = export_graphviz(tree,\n","                               feature_names=X_train.columns,\n","                               filled=True,\n","                               max_depth=2,\n","                               impurity=False,\n","                               proportion=True)\n","    graph = graphviz.Source(dot_data)\n","    display(graph)"],"metadata":{"id":"sn1Jjm8N0LBC","colab":{"base_uri":"https://localhost:8080/","height":856},"executionInfo":{"status":"error","timestamp":1705062474052,"user_tz":-60,"elapsed":466,"user":{"displayName":"H. Werner","userId":"11107641138698865980"}},"outputId":"9a5a80f7-69b9-40c4-ade9-50c0c45b89e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.0\n","Precision: 0.0\n","Recall: 0.0\n","Predicted Class Distribution:\n","10     3\n","94     2\n","49     2\n","17     1\n","73     1\n","58     1\n","24     1\n","41     1\n","43     1\n","101    1\n","18     1\n","25     1\n","3      1\n","2      1\n","39     1\n","64     1\n","71     1\n","dtype: int64\n","Confusion Matrix:\n","[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'columns'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-1e7ef60ef1ab>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     dot_data = export_graphviz(tree,\n\u001b[0;32m---> 56\u001b[0;31m                                \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                                \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                                \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"]}]},{"cell_type":"markdown","source":["# Why its not working - Ideas\n","\n","- Data Exploration\n","  - data is imbalanced -> oversampling, undersampling, different weights\n","- Data Preprocessing\n","  - missing values, outliers, feature scaling\n","- Model parameters\n","  - n_estimators, max_depth\n","- Use other classifier"],"metadata":{"id":"FWRNsW4BEOPA"}},{"cell_type":"markdown","source":["## Hyperparameter Tuning"],"metadata":{"id":"B6NUgifY3lET"}},{"cell_type":"code","source":["from sklearn.model_selection import StratifiedKFold\n","param_dist = {'n_estimators': randint(50,1000),\n","              'max_depth': randint(1,20)}\n","\n","# Create a random forest classifier\n","rf = RandomForestClassifier()\n","\n","# Use random search to find the best hyperparameters\n","rand_search = RandomizedSearchCV(rf,\n","                                 param_distributions = param_dist,\n","                                 n_iter=20,\n","                                 cv=2)\n","\n","# Fit the random search object to the data\n","rand_search.fit(X_train, y_train)"],"metadata":{"id":"R-rnojDa3j_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a variable for the best model\n","best_rf = rand_search.best_estimator_\n","\n","# Print the best hyperparameters\n","print('Best hyperparameters:',  rand_search.best_params_)"],"metadata":{"id":"_4yTHhQW3ty9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Evaluation\n"],"metadata":{"id":"me_lNF6bAwPA"}},{"cell_type":"code","source":["# Create the confusion matrix\n","cm = confusion_matrix(y_test, y_pred)\n","\n","ConfusionMatrixDisplay(confusion_matrix=cm).plot();"],"metadata":{"id":"zt3ERPcrAz8R","executionInfo":{"status":"error","timestamp":1705136616118,"user_tz":-60,"elapsed":259,"user":{"displayName":"H. Werner","userId":"11107641138698865980"}},"colab":{"base_uri":"https://localhost:8080/","height":233},"outputId":"3b2d9c65-e00f-4837-ed67-09c1e078b058"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'confusion_matrix' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-376bb8d54037>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"provenance":[{"file_id":"1ZZuHQzjugkFjm-wZ-l1u8wrN0FtR-Bwp","timestamp":1704886415133}]}},"nbformat":4,"nbformat_minor":0}